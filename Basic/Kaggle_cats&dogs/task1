import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from pandas import plotting
from scipy import stats
plt.style.use("ggplot")
import warnings
warnings.filterwarnings("ignore")
from scipy import stats

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

import os
print(pd.read_csv("/content/wdbc-titled"))
data = pd.read_csv("/content/wdbc-titled")
print("ok we have the data")
data.head()
#data.shape # (569, 31)
#data.columns 
data_bening = data[data["diagnosis"] == "B"]
data_malignant = data[data["diagnosis"] == "M"]
#lets look at effect sizes 
print("lets look at effect sizes")
mean_diff = data_malignant.mean_radius.mean() - data_bening.mean_radius.mean()
var_bening = data_bening.mean_radius.var()
var_malignant = data_malignant.mean_radius.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Mean Radius Effect size: ",effect_size)

mean_diff = data_malignant.SE_radius.mean() - data_bening.SE_radius.mean()
var_bening = data_bening.SE_radius.var()
var_malignant = data_malignant.SE_radius.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("SE Radius Effect size: ",effect_size)

mean_diff = data_malignant.worst_radius.mean() - data_bening.worst_radius.mean()
var_bening = data_bening.worst_radius.var()
var_malignant = data_malignant.worst_radius.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Worst Radius Effect size: ",effect_size)

mean_diff = data_malignant.mean_texture.mean() - data_bening.mean_texture.mean()
var_bening = data_bening.mean_texture.var()
var_malignant = data_malignant.mean_texture.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Mean Texture Effect size: ",effect_size)

mean_diff = data_malignant.SE_texture.mean() - data_bening.SE_texture.mean()
var_bening = data_bening.SE_texture.var()
var_malignant = data_malignant.SE_texture.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("SE Texture Effect size: ",effect_size)

mean_diff = data_malignant.worst_texture.mean() - data_bening.worst_texture.mean()
var_bening = data_bening.worst_texture.var()
var_malignant = data_malignant.worst_texture.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Worst Texture Effect size: ",effect_size)

mean_diff = data_malignant.mean_perimeter.mean() - data_bening.mean_perimeter.mean()
var_bening = data_bening.mean_perimeter.var()
var_malignant = data_malignant.mean_perimeter.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Mean Perimeter Effect size: ",effect_size)

mean_diff = data_malignant.SE_perimeter.mean() - data_bening.SE_perimeter.mean()
var_bening = data_bening.SE_perimeter.var()
var_malignant = data_malignant.SE_perimeter.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("SE Perimeter Effect size: ",effect_size)

mean_diff = data_malignant.worst_perimeter.mean() - data_bening.worst_perimeter.mean()
var_bening = data_bening.worst_perimeter.var()
var_malignant = data_malignant.worst_perimeter.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Worst Perimeter Effect size: ",effect_size)

mean_diff = data_malignant.mean_area.mean() - data_bening.mean_area.mean()
var_bening = data_bening.mean_area.var()
var_malignant = data_malignant.mean_area.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Mean Area Effect size: ",effect_size)

mean_diff = data_malignant.SE_area.mean() - data_bening.SE_area.mean()
var_bening = data_bening.SE_area.var()
var_malignant = data_malignant.SE_area.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("SE Area Effect size: ",effect_size)

mean_diff = data_malignant.worst_area.mean() - data_bening.worst_area.mean()
var_bening = data_bening.worst_area.var()
var_malignant = data_malignant.worst_area.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Worst Area Effect size: ",effect_size)

mean_diff = data_malignant.mean_smoothness.mean() - data_bening.mean_smoothness.mean()
var_bening = data_bening.mean_smoothness.var()
var_malignant = data_malignant.mean_smoothness.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Mean Smoothness Effect size: ",effect_size)

mean_diff = data_malignant.SE_smoothness.mean() - data_bening.SE_smoothness.mean()
var_bening = data_bening.SE_smoothness.var()
var_malignant = data_malignant.SE_smoothness.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("SE Smoothness Effect size: ",effect_size)

mean_diff = data_malignant.worst_smoothness.mean() - data_bening.worst_smoothness.mean()
var_bening = data_bening.worst_smoothness.var()
var_malignant = data_malignant.worst_smoothness.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Worst Smoothness Effect size: ",effect_size)

mean_diff = data_malignant.mean_compactness.mean() - data_bening.mean_compactness.mean()
var_bening = data_bening.mean_compactness.var()
var_malignant = data_malignant.mean_compactness.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Mean Compactness Effect size: ",effect_size)

mean_diff = data_malignant.SE_compactness.mean() - data_bening.SE_compactness.mean()
var_bening = data_bening.SE_compactness.var()
var_malignant = data_malignant.SE_compactness.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("SE Compactness Effect size: ",effect_size)

mean_diff = data_malignant.worst_compactness.mean() - data_bening.worst_compactness.mean()
var_bening = data_bening.worst_compactness.var()
var_malignant = data_malignant.worst_compactness.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Worst Compactness Effect size: ",effect_size)

mean_diff = data_malignant.mean_concavity.mean() - data_bening.mean_concavity.mean()
var_bening = data_bening.mean_concavity.var()
var_malignant = data_malignant.mean_concavity.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Mean Concavity Effect size: ",effect_size)

mean_diff = data_malignant.SE_concavity.mean() - data_bening.SE_concavity.mean()
var_bening = data_bening.SE_concavity.var()
var_malignant = data_malignant.SE_concavity.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("SE Concavity Effect size: ",effect_size)

mean_diff = data_malignant.worst_concavity.mean() - data_bening.worst_concavity.mean()
var_bening = data_bening.worst_concavity.var()
var_malignant = data_malignant.worst_concavity.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Worst Concavity Effect size: ",effect_size)

mean_diff = data_malignant.mean_concave_points.mean() - data_bening.mean_concave_points.mean()
var_bening = data_bening.mean_concave_points.var()
var_malignant = data_malignant.mean_concave_points.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Mean Concave Points Effect size: ",effect_size)

mean_diff = data_malignant.SE_concave_points.mean() - data_bening.SE_concave_points.mean()
var_bening = data_bening.SE_concave_points.var()
var_malignant = data_malignant.SE_concave_points.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("SE Concave Points Effect size: ",effect_size)

mean_diff = data_malignant.worst_concave_points.mean() - data_bening.worst_concave_points.mean()
var_bening = data_bening.worst_concave_points.var()
var_malignant = data_malignant.worst_concave_points.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Worst Concave Points Effect size: ",effect_size)

mean_diff = data_malignant.mean_symmetry.mean() - data_bening.mean_symmetry.mean()
var_bening = data_bening.mean_symmetry.var()
var_malignant = data_malignant.mean_symmetry.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Mean Symmetry Effect size: ",effect_size)

mean_diff = data_malignant.SE_symmetry.mean() - data_bening.SE_symmetry.mean()
var_bening = data_bening.SE_symmetry.var()
var_malignant = data_malignant.SE_symmetry.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("SE Symmetry Effect size: ",effect_size)

mean_diff = data_malignant.worst_symmetry.mean() - data_bening.worst_symmetry.mean()
var_bening = data_bening.worst_symmetry.var()
var_malignant = data_malignant.worst_symmetry.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Worst Symmetry Effect size: ",effect_size)

mean_diff = data_malignant.mean_fractal_dimension.mean() - data_bening.mean_fractal_dimension.mean()
var_bening = data_bening.mean_fractal_dimension.var()
var_malignant = data_malignant.mean_fractal_dimension.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Mean Fractal Dimension Effect size: ",effect_size)

mean_diff = data_malignant.SE_fractal_dimension.mean() - data_bening.SE_fractal_dimension.mean()
var_bening = data_bening.SE_fractal_dimension.var()
var_malignant = data_malignant.SE_fractal_dimension.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("SE Fractal Dimension Effect size: ",effect_size)

mean_diff = data_malignant.worst_fractal_dimension.mean() - data_bening.worst_fractal_dimension.mean()
var_bening = data_bening.worst_fractal_dimension.var()
var_malignant = data_malignant.worst_fractal_dimension.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Worst Fractal Dimension Effect size: ",effect_size)

#lets look at correlation
print("lets look at correlation")
f,ax=plt.subplots(figsize = (18,18))
sns.heatmap(data.corr(),annot= True,linewidths=0.5,fmt = ".1f",ax=ax)
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.title('Correlation Map')
plt.savefig('graph.png')
plt.show()

#lets get the 3 best features
print("lets get the 3 best features")
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score,confusion_matrix
from sklearn.metrics import accuracy_score

y = data.diagnosis                          # M or B 
listthedata = ['id_number','diagnosis']
x = data.drop(listthedata,axis = 1 )
# split data train 70 % and test 30 %
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)

#univariate feature selection

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
# find best scored 3 features
select_feature = SelectKBest(chi2, k=3).fit(x_train, y_train)
x_train_2 = select_feature.transform(x_train)
x_test_2 = select_feature.transform(x_test)
#random forest classifier with n_estimators=10 (default)
clf_rf_2 = RandomForestClassifier()      
clr_rf_2 = clf_rf_2.fit(x_train_2,y_train)
ac_2 = accuracy_score(y_test,clf_rf_2.predict(x_test_2))
print('Univariate Feature Selection Random Forest Accuracy is: ',ac_2)
cm_2 = confusion_matrix(y_test,clf_rf_2.predict(x_test_2))
#sns.heatmap(cm_2,annot=True,fmt="d")

#RFE
from sklearn.feature_selection import RFE
# Create the RFE object and rank each pixel
clf_rf_3 = RandomForestClassifier()   
clr_rf_3 = clf_rf_3.fit(x_train,y_train)   
rfe = RFE(estimator=clf_rf_3, n_features_to_select=3, step=1)
rfe = rfe.fit(x_train, y_train)
ac_3 = accuracy_score(y_test,clf_rf_3.predict(x_test))
print('RFE Random Forest Accuracy is: ',ac_3)
print('Chosen best 3 feature by rfe:',x_train.columns[rfe.support_])


kfeatures = data.drop(columns=['mean_radius','SE_radius', 'mean_texture', 'SE_texture','worst_texture', 'SE_perimeter','mean_perimeter','worst_perimeter', 'SE_area', 'mean_area','mean_smoothness', 'SE_smoothness', 'worst_smoothness', 'SE_compactness','mean_compactness','worst_compactness', 'SE_concavity','mean_concavity','worst_concavity', 'SE_concave_points','worst_concave_points', 'mean_symmetry', 'SE_symmetry', 'worst_symmetry', 'mean_fractal_dimension', 'SE_fractal_dimension', 'worst_fractal_dimension'])
#kfeatures.head()
#y = kfeatures.diagnosis  
#ax = sns.countplot(y,label="Count")       # M = 212, B = 357
#B, M = y.value_counts()
#print('Number of Benign: ',B)
#print('Number of Malignant : ',M)
kfeatures.describe()

#lets gather info on the chosen 3 best features: worst_radius, worst_area, and worst_concave_points
print("lets gather info on the chosen 3 best features: worst_radius, worst_area, and worst_concave_points")
#look at relationship between more than 2 variables
sns.set(style = "white")
df = data.loc[:,["worst_radius","worst_area","worst_concave_points"]]
g = sns.PairGrid(df,diag_sharey = False,)
g.map_lower(sns.kdeplot,cmap="Blues_d")
g.map_upper(plt.scatter)
g.map_diag(sns.kdeplot,lw =3)
plt.show()

#worst radius
print("worst radius")
m = plt.hist(data[data["diagnosis"] == "M"].worst_radius,bins=30,fc = (1,0,0,0.5),label = "Malignant")
b = plt.hist(data[data["diagnosis"] == "B"].worst_radius,bins=30,fc = (0,1,0,0.5),label = "Bening")
plt.legend()
plt.xlabel("Radius Worst Values")
plt.ylabel("Frequency")
plt.title("Histogram of Worst Radius for Bening and Malignant Tumors")
plt.show()
frequent_malignant_worst_radius = m[0].max()
index_frequent_malignant_worst_radius = list(m[0]).index(frequent_malignant_worst_radius)
most_frequent_malignant_worst_radius = m[1][index_frequent_malignant_worst_radius]
print("Most frequent malignant worst radius is: ",most_frequent_malignant_worst_radius)

data_bening = data[data["diagnosis"] == "B"]
data_malignant = data[data["diagnosis"] == "M"]
desc = data_bening.worst_radius.describe()
Q1 = desc[4]
Q3 = desc[6]
IQR = Q3-Q1
lower_bound = Q1 - 1.5*IQR
upper_bound = Q3 + 1.5*IQR
print("Anything outside this range is an outlier: (", lower_bound ,",", upper_bound,")")
data_bening[data_bening.worst_radius < lower_bound].worst_radius
print("Outliers: ",data_bening[(data_bening.worst_radius < lower_bound) | (data_bening.worst_radius > upper_bound)].worst_radius.values)

melted_data = pd.melt(data,id_vars = "diagnosis",value_vars = ['worst_radius'])
plt.figure(figsize = (15,10))
sns.boxplot(x = "variable", y = "value", hue="diagnosis",data= melted_data)
plt.show()

print("mean: ",data_bening.worst_radius.mean())
print("variance: ",data_bening.worst_radius.var())
print("standart deviation (std): ",data_bening.worst_radius.std())
print("describe method: ",data_bening.worst_radius.describe())

plt.hist(data_bening.worst_radius,bins=50,fc=(0,1,0,0.5),label='Bening',normed = True,cumulative = True)
sorted_data = np.sort(data_bening.worst_radius)
y = np.arange(len(sorted_data))/float(len(sorted_data)-1)
plt.plot(sorted_data,y,color='red')
plt.title('CDF of bening tumor worst radius')
plt.show()

mean_diff = data_malignant.worst_radius.mean() - data_bening.worst_radius.mean()
var_bening = data_bening.worst_radius.var()
var_malignant = data_malignant.worst_radius.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Effect size: ",effect_size)


#worst area
print("worst area")
m = plt.hist(data[data["diagnosis"] == "M"].worst_area,bins=30,fc = (1,0,0,0.5),label = "Malignant")
b = plt.hist(data[data["diagnosis"] == "B"].worst_area,bins=30,fc = (0,1,0,0.5),label = "Bening")
plt.legend()
plt.xlabel("Worst area Values")
plt.ylabel("Frequency")
plt.title("Histogram of Worst area for Bening and Malignant Tumors")
plt.show()
frequent_malignant_worst_area = m[0].max()
index_frequent_malignant_worst_area = list(m[0]).index(frequent_malignant_worst_area)
most_frequent_malignant_worst_area = m[1][index_frequent_malignant_worst_area]
print("Most frequent malignant worst area is: ",most_frequent_malignant_worst_area)

data_bening = data[data["diagnosis"] == "B"]
data_malignant = data[data["diagnosis"] == "M"]
desc = data_bening.worst_area.describe()
Q1 = desc[4]
Q3 = desc[6]
IQR = Q3-Q1
lower_bound = Q1 - 1.5*IQR
upper_bound = Q3 + 1.5*IQR
print("Anything outside this range is an outlier: (", lower_bound ,",", upper_bound,")")
data_bening[data_bening.worst_area < lower_bound].worst_area
print("Outliers: ",data_bening[(data_bening.worst_area < lower_bound) | (data_bening.worst_area > upper_bound)].worst_area.values)

melted_data = pd.melt(data,id_vars = "diagnosis",value_vars = ['worst_area'])
plt.figure(figsize = (15,10))
sns.boxplot(x = "variable", y = "value", hue="diagnosis",data= melted_data)
plt.show()

print("mean: ",data_bening.worst_area.mean())
print("variance: ",data_bening.worst_area.var())
print("standart deviation (std): ",data_bening.worst_area.std())
print("describe method: ",data_bening.worst_area.describe())

plt.hist(data_bening.worst_area,bins=50,fc=(0,1,0,0.5),label='Bening',normed = True,cumulative = True)
sorted_data = np.sort(data_bening.worst_area)
y = np.arange(len(sorted_data))/float(len(sorted_data)-1)
plt.plot(sorted_data,y,color='red')
plt.title('CDF of bening tumor worst area')
plt.show()

mean_diff = data_malignant.worst_area.mean() - data_bening.worst_area.mean()
var_bening = data_bening.worst_area.var()
var_malignant = data_malignant.worst_area.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Effect size: ",effect_size)


#worst concave points
print("worst concave points")
m = plt.hist(data[data["diagnosis"] == "M"].worst_concave_points,bins=30,fc = (1,0,0,0.5),label = "Malignant")
b = plt.hist(data[data["diagnosis"] == "B"].worst_concave_points,bins=30,fc = (0,1,0,0.5),label = "Bening")
plt.legend()
plt.xlabel("Worst Concave Points Values")
plt.ylabel("Frequency")
plt.title("Histogram of Worst Concave Points for Bening and Malignant Tumors")
plt.show()
frequent_malignant_worst_concave_points = m[0].max()
index_frequent_malignant_worst_concave_points = list(m[0]).index(frequent_malignant_worst_concave_points)
most_frequent_malignant_worst_concave_points = m[1][index_frequent_malignant_worst_concave_points]
print("Most frequent malignant worst concave points is: ",most_frequent_malignant_worst_concave_points)

data_bening = data[data["diagnosis"] == "B"]
data_malignant = data[data["diagnosis"] == "M"]
desc = data_bening.worst_concave_points.describe()
Q1 = desc[4]
Q3 = desc[6]
IQR = Q3-Q1
lower_bound = Q1 - 1.5*IQR
upper_bound = Q3 + 1.5*IQR
print("Anything outside this range is an outlier: (", lower_bound ,",", upper_bound,")")
data_bening[data_bening.worst_concave_points < lower_bound].worst_concave_points
print("Outliers: ",data_bening[(data_bening.worst_concave_points < lower_bound) | (data_bening.worst_concave_points > upper_bound)].worst_concave_points)

melted_data = pd.melt(data,id_vars = "diagnosis",value_vars = ['worst_concave_points'])
plt.figure(figsize = (15,10))
sns.boxplot(x = "variable", y = "value", hue="diagnosis",data= melted_data)
plt.show()

print("mean: ",data_bening.worst_concave_points.mean())
print("variance: ",data_bening.worst_concave_points.var())
print("standart deviation (std): ",data_bening.worst_concave_points.std())
print("describe method: ",data_bening.worst_concave_points.describe())

plt.hist(data_bening.worst_concave_points,bins=50,fc=(0,1,0,0.5),label='Bening',normed = True,cumulative = True)
sorted_data = np.sort(data_bening.worst_concave_points)
y = np.arange(len(sorted_data))/float(len(sorted_data)-1)
plt.plot(sorted_data,y,color='red')
plt.title('CDF of bening tumor worst concave points')
plt.show()

mean_diff = data_malignant.worst_concave_points.mean() - data_bening.worst_concave_points.mean()
var_bening = data_bening.worst_concave_points.var()
var_malignant = data_malignant.worst_concave_points.var()
var_pooled = (len(data_bening)*var_bening +len(data_malignant)*var_malignant ) / float(len(data_bening)+ len(data_malignant))
effect_size = mean_diff/np.sqrt(var_pooled)
print("Effect size: ",effect_size)

#finally, train 2 classifiers using these 3 features
print("finally, train 2 classifiers using these 3 features")
kfeatures = data.drop(columns=['mean_radius','SE_radius', 'mean_texture', 'SE_texture','worst_texture', 'SE_perimeter','mean_perimeter','worst_perimeter', 'SE_area', 'mean_area','mean_smoothness', 'SE_smoothness', 'worst_smoothness', 'SE_compactness','mean_compactness','worst_compactness', 'SE_concavity','mean_concavity','worst_concavity', 'SE_concave_points','worst_concave_points', 'mean_symmetry', 'SE_symmetry', 'worst_symmetry', 'mean_fractal_dimension', 'SE_fractal_dimension', 'worst_fractal_dimension'])
kfeatures.head()
y = kfeatures.diagnosis  
#ax = sns.countplot(y,label="Count")       # M = 212, B = 357
B, M = y.value_counts()
#print('Number of Benign: ',B)
#print('Number of Malignant : ',M)
kfeatures.describe()

from sklearn.utils import shuffle
# RANDOM FOREST
from sklearn.ensemble import RandomForestClassifier
kfeatures2 = kfeatures.drop(columns=['id_number'])
data_cols = [col for col in kfeatures2.columns if col != "diagnosis"]
kf_shfl = shuffle(kfeatures2)
X = kf_shfl[data_cols].values
Y = kf_shfl["diagnosis"].values
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)
model = RandomForestClassifier()  
model.fit(X_train, Y_train)
result = model.score(X_test, Y_test)
print(("Random Forest Accuracy: %.2f%%") % (result*100.00))

# SVM
from sklearn import svm
kfeatures3 = kfeatures.drop(columns=['id_number'])
data_cols3 = [col for col in kfeatures3.columns if col != "diagnosis"]
kf_shfl2 = shuffle(kfeatures3)
X2 = kf_shfl2[data_cols3].values
Y2 = kf_shfl2["diagnosis"].values
X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X2, Y2, test_size=0.2)
model2 = svm.SVC()  
model2.fit(X_train2, Y_train2)
result2 = model2.score(X_test2, Y_test2)
print(("SVM Accuracy: %.2f%%") % (result2*100.00))